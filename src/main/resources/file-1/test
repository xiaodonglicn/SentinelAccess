
    1.低代码平台建设-流程编排
    内容：有一些逻辑简单的需求通过流程编排可以实现快速上线和部署，省去了直接编写代码的步骤，让需求实现更为简单和便利，通过对流程的编排
    开发工具：
    主要技术：
    担任角色：
    负责工作：
    业绩：解决了什么问题，达到了什么成就


    // 2.DragonflyDB调研

    内容：要求对找到一款对redis平替的中间件，改动成本尽量降到最低，DragonflyDB兼容Redis协议，并支持持久化，支持Redis的命令和数据模型
    开发工具：
    主要技术：
    担任角色：
    负责工作：
    业绩：解决了什么问题，达到了什么成就

    // 3.Apache NiFi调研与切换
    内容：Apache NiFi 是一个强大的ETL数据流自动化工具，用于在不同系统之间进行高效、可靠的数据传输和处理。
    它提供了可视化的界面来设计和管理数据流，并支持复杂的数据路由、转换和系统中介逻辑。
    开发工具：
    主要技术：
    担任角色：高级开发工程师
    负责工作：调研NiFi的运行原理、使用场景，性能瓶颈，做出接入文档和多种使用方式的demo
    业绩：通过Apache NiFi创建的流程，将mysql的数据经过中途的转化和计算同步到StarRocks宽表，业务方直接对StarRocks宽表进行查询，
    极大的提高了查询速度

    // 4.时序数据库-IoTDB调研及底层API封装
    内容：Apache IoTDB 是一个轻量级、高性能、低成本、专为时序数据设计的一体化数据库，适用于物联网（IoT）场景。
    它集成了数据采集、存储、分析和可视化功能，支持边缘计算与云端协同。
    开发工具：
    主要技术：
    担任角色：
    负责工作：
    业绩：解决了什么问题，达到了什么成就

    // 5.轻量化-kafka？
    内容：
    开发工具：
    主要技术：
    担任角色：
    负责工作：
    业绩：解决了什么问题，达到了什么成就

    // 6.PolarDB
    内容：
    开发工具：
    主要技术：
    担任角色：
    负责工作：
    业绩：解决了什么问题，达到了什么成就


    // 7.核化工-交付
    内容：通过对现有数据、文件、三维模型的选择，后将选中的数据打包交付到另外一个平台，另外平台进行处理后提资。
    开发工具：
    主要技术：
    担任角色：
    负责工作：
    业绩：解决了什么问题，达到了什么成就



    -----------------------------
    电缆类：电缆型号、电缆路径、电缆长度、电缆特性代码
    设备类：防爆等级、放射性、废气量、抗震级别

    // 8、数据提资履历
    内容：首先定义对象的标准，如某些对象类下有哪些属性，如，设备类下有阀门、泵、放射性等属性，提资方通过约定好的标准将每个对象下的实例数据拼接为JSON格式，
        通过提资将结构化的数据请求到数据中台，数据中台通过程序的处理（ETL），将数据转化到大宽表（StarRocks），业务方通过对大宽表的查询实现自身业务需求；
        不同的项目通过分库做数据分流和数据隔离、多租户权限控制，
        核心流程：业务方调用接口将结构化数据JSON传输进来，服务端将数据存入kafka，消费端将JSON数据消息体获取到，转化为StarRocks横表所需结构，
            通过StarRocks的Stream Load模式将数据存入StarRocks，下游业务方（风控组、算法组）在StarRocks横表中对数据进行采样和分析


    开发工具：
    主要技术：kafka、StarRocks、（Apache NiFi）、（PolarDB）、（Apache IoTDB）
    担任角色：
    负责工作：
    业绩：解决了什么问题，达到了什么成就





使用kafka，每个消息中instances放入1000条数据，每天10亿数据量，就有1000000条消息，开4个消费者去消费消息，然后将实例数据转化到大宽表

    关键性能指标评估
    0. 业务方调用数据中台接口将数据放入kafka，10亿数据量约12分钟
    1. Kafka 生产端压力
    每天 100 万条消息，平均每秒约 11.5 条（1000000 / 86400 ≈ 11.5）
    如果有流量高峰（如集中在几小时内），需做限流或缓冲处理。
    2. Kafka 消费端能力
    假设每个消费者每秒能处理 300 条消息：
        4 个消费者总共可处理：4 × 300 = 1200 条/秒
        每天可处理消息：1200 × 86400 ≈ 1.03 亿条/天
        对应实例数量：1.03 亿 × 1000 = 103 亿条/天
    3. 消费端StarRocks插入性能
        StarRocks配置：
            FE 配置：至少 2 台（主备），内存 ≥ 64GB
            BE 配置：CPU ≥ 16 核，内存 ≥ 64GB，SSD 磁盘
            导入并发数：控制在 20~50 并发以内，避免 BE 过载
            JVM 参数：-Xms30g -Xmx30g（防止频繁 GC）
        插入性能：
            高配集群 + Stream Load，10亿条数据约23分钟（执行失败的消息放入kafka失败队列执行补偿，补偿再次失败需要将失败的消息体发给业务方，让其改结构重新提资）

    4.业务方如何使用大宽表
        风控组：异常检测、行为追踪、模型训练
        算法组：设备画像、行为建模、标签生成、汇总统计、趋势分析、可视化展示


1.提资接收接口：做限流，防止调用太频繁，将服务打爆；业务方调用数据中台接口将数据放入kafka，10亿数据量总耗时约19分钟
2.kafka消息消费：
    Kafka Broker：num.partitions=4, default.replication.factor=2, message.max.bytes=10MB
    Producer：batch.size=16384, linger.ms=10, enable.idempotence=true
    Consumer：fetch.min.bytes=1MB, max.poll.records=500, enable.auto.commit=false
    JVM：-Xms30g -Xmx30g，G1GC
3.StarRocks插入：
    FE 配置：至少 2 台（主备），内存 ≥ 64GB
    BE 配置：CPU ≥ 16 核，内存 ≥ 64GB，SSD 磁盘
    导入并发数：控制在 20~50 并发以内，避免 BE 过载
    JVM 参数：-Xms30g -Xmx30g（防止频繁 GC）
    插入方案：集群 + Stream Load，10亿条数据约23分钟，
4.整体流程：
    4.1 从kafka获取消息体JSON
    4.1 JSON解析提取实例数据转化未StarRocks需要的JSON格式
    4.1 插入StarRocks，使用Stream Load方式，
        4.1.1 使用 Stream Load 插入 10,000 条记录可能只需 20ms
        4.1.2 使用 10,000 条 INSERT 语句则可能需要 几秒甚至十几秒






[
    {
        "owner": "任务管理系统",
        "projectCode": "PROJECTM",
        "instances": [
            {
                "instanceCode": "aasasasa54555338",
                "objectModelCode": "FILE",
                "version": "A版",
                "attributes": [
                    {
                        "attributeModelCode": "TASK_NO",
                        "value": "202502198888"
                    },
                    {
                        "attributeModelCode": "FILE_NAME",
                        "value": "名称-77777"
                    },
                    {
                        "attributeModelCode": "FILE_PATH",
                        "value": "name-77777"
                    }
                ]
            }
        ]
    }
]





